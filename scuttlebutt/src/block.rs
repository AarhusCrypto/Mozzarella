// -*- mode: rust; -*-
//
// This file is part of `scuttlebutt`.
// Copyright Â© 2019 Galois, Inc.
// See LICENSE for licensing information.

//! Defines a block as a 128-bit value, and implements block-related functions.

#[cfg(feature = "curve25519-dalek")]
use crate::Aes256;
#[cfg(feature = "curve25519-dalek")]
use curve25519_dalek::ristretto::RistrettoPoint;
use std::{
    arch::x86_64::*,
    hash::{Hash, Hasher},
};

/// Interpret a block as an element of the field F_{2^128}
#[derive(Copy, Clone, Debug, Default, Eq, PartialEq)]
pub struct F128(Block);

impl F128 {
    pub fn one() -> Self {
        Self(Block(ONE))
    }

    pub fn zero() -> Self {
        Self(Block(ZERO))
    }

    /// Multiply by the field element X \in GF_{2}[X] / (X^128 + X^7 + X^2 + X + 1 )
    ///
    /// Not constant time!
    pub fn mul_x(self) -> Self {
        Self(Block(unsafe {
            let h = _mm_extract_epi64::<1>(self.0 .0) as u64;
            let l = _mm_extract_epi64::<0>(self.0 .0) as u64;
            let c_h = h >> 63;
            let c_l = l >> 63;
            debug_assert!(c_h < 2);
            debug_assert!(c_l < 2);
            let l = if c_h == 1 {
                (l << 1) ^ 0b100000000010000111
            } else {
                l << 1
            };
            let h = (h << 1) | c_l;
            _mm_set_epi64x(h as i64, l as i64)
        }))
    }
}

impl From<F128> for Block {
    #[inline]
    fn from(f: F128) -> Self {
        f.0
    }
}

impl From<Block> for F128 {
    #[inline]
    fn from(block: Block) -> Self {
        Self(block)
    }
}

impl Into<[bool; 128]> for Block {
    #[inline]
    fn into(self) -> [bool; 128] {
        let mut out: [bool; 128] = [Default::default(); 128];
        unsafe {
            let mut h = _mm_extract_epi64::<1>(self.0);
            let mut l = _mm_extract_epi64::<0>(self.0);
            let mut i = 63;
            let mut j = 127;
            loop {
                out[i] = (h & 1) != 0;
                out[j] = (l & 1) != 0;
                if i == 0 {
                    break;
                }
                i -= 1;
                j -= 1;
                h >>= 1;
                l >>= 1;
            }
        }
        out
    }
}

impl std::ops::Add for F128 {
    type Output = Self;

    #[inline]
    fn add(self, other: F128) -> F128 {
        F128(self.0 ^ other.0)
    }
}

impl std::ops::Sub for F128 {
    type Output = Self;

    #[inline]
    fn sub(self, other: F128) -> F128 {
        F128(self.0 ^ other.0)
    }
}

impl F128 {
    #[inline(always)]
    pub fn cmul(&self, other: F128) -> (Block, Block) {
        self.0.clmul(other.0)
    }

    #[inline(always)]
    #[allow(non_snake_case)]
    pub fn reduce(prod: (Block, Block)) -> F128 {
        #[inline(always)]
        unsafe fn shift_pack<const L: usize>(h: i64, l: i64) -> __m128i {
            let h = h as u64;
            let l = l as u64;
            let c = l >> (64 - L);
            let h = h << L;
            let l = l << L;
            debug_assert!(L < 64);
            debug_assert!(c < (1 << L));
            _mm_set_epi64x((h | c) as i64, l as i64)
        }

        let (l, h) = prod;
        F128(Block(unsafe {
            let X3 = _mm_extract_epi64::<1>(h.0);
            let X2 = _mm_extract_epi64::<0>(h.0);
            debug_assert!({
                let a = _mm_set_epi64x(X3, X2);
                let neq = _mm_xor_si128(a, h.0);
                _mm_test_all_zeros(neq, neq) != 0
            });
            let A = X3 >> 63;
            let B = X3 >> 62;
            let C = X3 >> 57;
            let D = X2 ^ A ^ B ^ C;
            let X3D = _mm_set_epi64x(X3, D);

            let E1E0 = shift_pack::<1>(X3, D);
            let F1F0 = shift_pack::<2>(X3, D);
            let G1G0 = shift_pack::<7>(X3, D);

            //
            let H1H0 = _mm_xor_si128(X3D, E1E0);
            let H1H0 = _mm_xor_si128(H1H0, F1F0);
            let H1H0 = _mm_xor_si128(H1H0, G1G0);
            _mm_xor_si128(l.0, H1H0)
        }))
    }
}

impl std::ops::Mul for F128 {
    type Output = Self;

    /// gfmul : Figure 5.
    #[inline(always)]
    fn mul(self, rhs: F128) -> F128 {
        F128::reduce(self.cmul(rhs))
    }
}

/// A 128-bit chunk.
#[derive(Clone, Copy)]
pub struct Block(pub __m128i);

union __U128 {
    vector: __m128i,
    bytes: u128,
}

const ZERO: __m128i = unsafe { (__U128 { bytes: 0 }).vector };
const ONE: __m128i = unsafe { (__U128 { bytes: 1 }).vector };
const ONES: __m128i = unsafe {
    (__U128 {
        bytes: 0xFFFF_FFFF_FFFF_FFFF_FFFF_FFFF_FFFF_FFFF,
    })
    .vector
};

impl<'a> From<&'a [bool; 128]> for Block {
    fn from(bits: &[bool; 128]) -> Self {
        let mut h: i64 = 0;
        let mut l: i64 = 0;
        for i in 0..64 {
            h <<= 1;
            l <<= 1;
            h |= bits[i] as i64;
            l |= bits[i + 64] as i64;
        }
        Block(unsafe { _mm_set_epi64x(h, l) })
    }
}

impl Into<Block> for (u64, u64) {
    fn into(self) -> Block {
        Block(unsafe { _mm_set_epi64x(self.0 as i64, self.1 as i64) })
    }
}

impl Block {
    /// Convert into a pointer.
    #[inline]
    pub fn as_ptr(&self) -> *const u8 {
        self.as_ref().as_ptr()
    }

    /// Convert into a mutable pointer.
    #[inline]
    pub fn as_mut_ptr(&mut self) -> *mut u8 {
        self.as_mut().as_mut_ptr()
    }

    /// Carryless multiplication.
    ///
    /// This code is adapted from the EMP toolkit's implementation.
    #[inline]
    pub fn clmul(self, rhs: Self) -> (Self, Self) {
        unsafe {
            let x = self.0;
            let y = rhs.0;
            let zero = _mm_clmulepi64_si128(x, y, 0x00);
            let one = _mm_clmulepi64_si128(x, y, 0x10);
            let two = _mm_clmulepi64_si128(x, y, 0x01);
            let three = _mm_clmulepi64_si128(x, y, 0x11);
            let tmp = _mm_xor_si128(one, two);
            let ll = _mm_slli_si128(tmp, 8);
            let rl = _mm_srli_si128(tmp, 8);
            let x = _mm_xor_si128(zero, ll);
            let y = _mm_xor_si128(three, rl);
            (Block(x), Block(y))
        }
    }

    /// Hash an elliptic curve point `pt` and tweak `tweak`.
    ///
    /// Computes the hash by computing `E_{pt}(tweak)`, where `E` is AES-256.
    #[cfg(feature = "curve25519-dalek")]
    #[inline]
    pub fn hash_pt(tweak: u128, pt: &RistrettoPoint) -> Self {
        let k = pt.compress();
        let c = Aes256::new(k.as_bytes());
        c.encrypt(Block::from(tweak))
    }

    /// Return the least significant bit.
    #[inline]
    pub fn lsb(&self) -> bool {
        unsafe { _mm_extract_epi8(_mm_and_si128(self.0, ONE), 0) == 1 }
    }

    /// Set the least significant bit.
    #[inline]
    pub fn set_lsb(&self) -> Block {
        unsafe { Block(_mm_or_si128(self.0, ONE)) }
    }

    /// Flip all bits.
    #[inline]
    pub fn flip(&self) -> Self {
        unsafe { Block(_mm_xor_si128(self.0, ONES)) }
    }

    /// Try to create a `Block` from a slice of bytes. The slice must have exactly 16 bytes.
    #[inline]
    pub fn try_from_slice(bytes_slice: &[u8]) -> Option<Self> {
        if bytes_slice.len() != 16 {
            return None;
        }
        let mut bytes = [0; 16];
        bytes[..16].clone_from_slice(&bytes_slice[..16]);
        Some(Block::from(bytes))
    }
}

impl Default for Block {
    #[inline]
    fn default() -> Self {
        unsafe { Block(_mm_setzero_si128()) }
    }
}

impl PartialEq for Block {
    #[inline]
    fn eq(&self, other: &Block) -> bool {
        unsafe {
            let neq = _mm_xor_si128(self.0, other.0);
            _mm_test_all_zeros(neq, neq) != 0
        }
    }
}

impl Eq for Block {}

impl Ord for Block {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        u128::from(*self).cmp(&u128::from(*other))
    }
}

impl PartialOrd for Block {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(u128::from(*self).cmp(&u128::from(*other)))
    }
}

impl AsRef<[u8]> for Block {
    #[inline]
    fn as_ref(&self) -> &[u8] {
        unsafe { &*(self as *const Block as *const [u8; 16]) }
    }
}

impl AsMut<[u8]> for Block {
    #[inline]
    fn as_mut(&mut self) -> &mut [u8] {
        unsafe { &mut *(self as *mut Block as *mut [u8; 16]) }
    }
}

impl std::ops::BitAnd for Block {
    type Output = Block;
    #[inline]
    fn bitand(self, rhs: Self) -> Self {
        unsafe { Block(_mm_and_si128(self.0, rhs.0)) }
    }
}

impl std::ops::BitAndAssign for Block {
    #[inline]
    fn bitand_assign(&mut self, rhs: Self) {
        unsafe { self.0 = _mm_and_si128(self.0, rhs.0) }
    }
}

impl std::ops::BitOr for Block {
    type Output = Block;
    #[inline]
    fn bitor(self, rhs: Self) -> Self {
        unsafe { Block(_mm_or_si128(self.0, rhs.0)) }
    }
}

impl std::ops::BitOrAssign for Block {
    #[inline]
    fn bitor_assign(&mut self, rhs: Self) {
        unsafe { self.0 = _mm_or_si128(self.0, rhs.0) }
    }
}

impl std::ops::BitXor for Block {
    type Output = Block;
    #[inline]
    fn bitxor(self, rhs: Self) -> Self {
        unsafe { Block(_mm_xor_si128(self.0, rhs.0)) }
    }
}

impl std::ops::BitXorAssign for Block {
    #[inline]
    fn bitxor_assign(&mut self, rhs: Self) {
        unsafe { self.0 = _mm_xor_si128(self.0, rhs.0) }
    }
}

impl std::fmt::Debug for Block {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        let val: u128 = (*self).into();
        write!(f, "{:032X}", val)
    }
}

impl std::fmt::Display for Block {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        let block: [u8; 16] = (*self).into();
        for byte in block.iter() {
            write!(f, "{:02X}", byte)?;
        }
        Ok(())
    }
}

impl rand::distributions::Distribution<Block> for rand::distributions::Standard {
    #[inline]
    fn sample<R: rand::Rng + ?Sized>(&self, rng: &mut R) -> Block {
        Block::from(rng.gen::<u128>())
    }
}

impl From<Block> for u128 {
    #[inline]
    fn from(m: Block) -> u128 {
        unsafe { *(&m as *const _ as *const u128) }
    }
}

impl From<u128> for Block {
    #[inline]
    fn from(m: u128) -> Self {
        unsafe { std::mem::transmute(m) }
        // XXX: the below doesn't work due to pointer-alignment issues.
        // unsafe { *(&m as *const _ as *const Block) }
    }
}

impl From<Block> for __m128i {
    #[inline]
    fn from(m: Block) -> __m128i {
        m.0
    }
}

impl From<__m128i> for Block {
    #[inline]
    fn from(m: __m128i) -> Self {
        Block(m)
    }
}

impl From<Block> for [u8; 16] {
    #[inline]
    fn from(m: Block) -> [u8; 16] {
        unsafe { *(&m as *const _ as *const [u8; 16]) }
    }
}

impl From<[u8; 16]> for Block {
    #[inline]
    fn from(m: [u8; 16]) -> Self {
        unsafe { std::mem::transmute(m) }
        // XXX: the below doesn't work due to pointer-alignment issues.
        // unsafe { *(&m as *const _ as *const Block) }
    }
}

impl From<[u16; 8]> for Block {
    #[inline]
    fn from(m: [u16; 8]) -> Self {
        unsafe { std::mem::transmute(m) }
    }
}

impl From<Block> for [u32; 4] {
    #[inline]
    fn from(m: Block) -> Self {
        unsafe { *(&m as *const _ as *const [u32; 4]) }
    }
}

impl Hash for Block {
    fn hash<H: Hasher>(&self, state: &mut H) {
        let v: u128 = (*self).into();
        v.hash(state);
    }
}

#[cfg(feature = "serde")]
use serde::{Deserialize, Deserializer, Serialize, Serializer};

#[cfg(feature = "serde")]
#[derive(Serialize, Deserialize)]
struct Helperb {
    pub block: u128,
}

#[cfg(feature = "serde")]
impl Serialize for Block {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: Serializer,
    {
        let helper = Helperb {
            block: <u128>::from(*self),
        };
        helper.serialize(serializer)
    }
}

#[cfg(feature = "serde")]
impl<'de> Deserialize<'de> for Block {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: Deserializer<'de>,
    {
        let helper = Helperb::deserialize(deserializer)?;
        Ok(Block::from(helper.block.to_le_bytes()))
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use rand::{rngs::OsRng, Rng};

    #[test]
    fn test_bits_block() {
        for _ in 0..10 {
            let block: Block = OsRng.gen();
            let bits: [bool; 128] = block.into();
            let block_p: Block = (&bits).into();
            assert_eq!(block, block_p);
        }
    }

    #[test]
    fn test_gf128_mul() {
        let tests: Vec<(u128, u128, u128)> = vec![
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000001,
                0x00000000000000000000000000000002,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000004,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000004,
                0x00000000000000000000000000000008,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000008,
                0x00000000000000000000000000000010,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000010,
                0x00000000000000000000000000000020,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000020,
                0x00000000000000000000000000000040,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000040,
                0x00000000000000000000000000000080,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000080,
                0x00000000000000000000000000000100,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000100,
                0x00000000000000000000000000000200,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000200,
                0x00000000000000000000000000000400,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000400,
                0x00000000000000000000000000000800,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000000800,
                0x00000000000000000000000000001000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000001000,
                0x00000000000000000000000000002000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000002000,
                0x00000000000000000000000000004000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000004000,
                0x00000000000000000000000000008000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000008000,
                0x00000000000000000000000000010000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000010000,
                0x00000000000000000000000000020000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000020000,
                0x00000000000000000000000000040000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000040000,
                0x00000000000000000000000000080000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000080000,
                0x00000000000000000000000000100000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000100000,
                0x00000000000000000000000000200000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000200000,
                0x00000000000000000000000000400000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000400000,
                0x00000000000000000000000000800000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000000800000,
                0x00000000000000000000000001000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000001000000,
                0x00000000000000000000000002000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000002000000,
                0x00000000000000000000000004000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000004000000,
                0x00000000000000000000000008000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000008000000,
                0x00000000000000000000000010000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000010000000,
                0x00000000000000000000000020000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000020000000,
                0x00000000000000000000000040000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000040000000,
                0x00000000000000000000000080000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000080000000,
                0x00000000000000000000000100000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000100000000,
                0x00000000000000000000000200000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000200000000,
                0x00000000000000000000000400000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000400000000,
                0x00000000000000000000000800000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000000800000000,
                0x00000000000000000000001000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000001000000000,
                0x00000000000000000000002000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000002000000000,
                0x00000000000000000000004000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000004000000000,
                0x00000000000000000000008000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000008000000000,
                0x00000000000000000000010000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000010000000000,
                0x00000000000000000000020000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000020000000000,
                0x00000000000000000000040000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000040000000000,
                0x00000000000000000000080000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000080000000000,
                0x00000000000000000000100000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000100000000000,
                0x00000000000000000000200000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000200000000000,
                0x00000000000000000000400000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000400000000000,
                0x00000000000000000000800000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000000800000000000,
                0x00000000000000000001000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000001000000000000,
                0x00000000000000000002000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000002000000000000,
                0x00000000000000000004000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000004000000000000,
                0x00000000000000000008000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000008000000000000,
                0x00000000000000000010000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000010000000000000,
                0x00000000000000000020000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000020000000000000,
                0x00000000000000000040000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000040000000000000,
                0x00000000000000000080000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000080000000000000,
                0x00000000000000000100000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000100000000000000,
                0x00000000000000000200000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000200000000000000,
                0x00000000000000000400000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000400000000000000,
                0x00000000000000000800000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000000800000000000000,
                0x00000000000000001000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000001000000000000000,
                0x00000000000000002000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000002000000000000000,
                0x00000000000000004000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000004000000000000000,
                0x00000000000000008000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000008000000000000000,
                0x00000000000000010000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000010000000000000000,
                0x00000000000000020000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000020000000000000000,
                0x00000000000000040000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000040000000000000000,
                0x00000000000000080000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000080000000000000000,
                0x00000000000000100000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000100000000000000000,
                0x00000000000000200000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000200000000000000000,
                0x00000000000000400000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000400000000000000000,
                0x00000000000000800000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000000800000000000000000,
                0x00000000000001000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000001000000000000000000,
                0x00000000000002000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000002000000000000000000,
                0x00000000000004000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000004000000000000000000,
                0x00000000000008000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000008000000000000000000,
                0x00000000000010000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000010000000000000000000,
                0x00000000000020000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000020000000000000000000,
                0x00000000000040000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000040000000000000000000,
                0x00000000000080000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000080000000000000000000,
                0x00000000000100000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000100000000000000000000,
                0x00000000000200000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000200000000000000000000,
                0x00000000000400000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000400000000000000000000,
                0x00000000000800000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000000800000000000000000000,
                0x00000000001000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000001000000000000000000000,
                0x00000000002000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000002000000000000000000000,
                0x00000000004000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000004000000000000000000000,
                0x00000000008000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000008000000000000000000000,
                0x00000000010000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000010000000000000000000000,
                0x00000000020000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000020000000000000000000000,
                0x00000000040000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000040000000000000000000000,
                0x00000000080000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000080000000000000000000000,
                0x00000000100000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000100000000000000000000000,
                0x00000000200000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000200000000000000000000000,
                0x00000000400000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000400000000000000000000000,
                0x00000000800000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000000800000000000000000000000,
                0x00000001000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000001000000000000000000000000,
                0x00000002000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000002000000000000000000000000,
                0x00000004000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000004000000000000000000000000,
                0x00000008000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000008000000000000000000000000,
                0x00000010000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000010000000000000000000000000,
                0x00000020000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000020000000000000000000000000,
                0x00000040000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000040000000000000000000000000,
                0x00000080000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000080000000000000000000000000,
                0x00000100000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000100000000000000000000000000,
                0x00000200000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000200000000000000000000000000,
                0x00000400000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000400000000000000000000000000,
                0x00000800000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00000800000000000000000000000000,
                0x00001000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00001000000000000000000000000000,
                0x00002000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00002000000000000000000000000000,
                0x00004000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00004000000000000000000000000000,
                0x00008000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00008000000000000000000000000000,
                0x00010000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00010000000000000000000000000000,
                0x00020000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00020000000000000000000000000000,
                0x00040000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00040000000000000000000000000000,
                0x00080000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00080000000000000000000000000000,
                0x00100000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00100000000000000000000000000000,
                0x00200000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00200000000000000000000000000000,
                0x00400000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00400000000000000000000000000000,
                0x00800000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x00800000000000000000000000000000,
                0x01000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x01000000000000000000000000000000,
                0x02000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x02000000000000000000000000000000,
                0x04000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x04000000000000000000000000000000,
                0x08000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x08000000000000000000000000000000,
                0x10000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x10000000000000000000000000000000,
                0x20000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x20000000000000000000000000000000,
                0x40000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x40000000000000000000000000000000,
                0x80000000000000000000000000000000,
            ),
            (
                0x00000000000000000000000000000002,
                0x80000000000000000000000000000000,
                0x00000000000000000000000000000087,
            ),
            (
                0x00593c1eca9a5abe6dac284196d57be5,
                0x2966222a9ac54973f3919363a1df59a5,
                0x12790d18ae3af0d3d366f46cc552a6b3,
            ),
            (
                0x47c5d6c6f60adb595fa98c8836292c15,
                0xf20c5c40bafae9d57dd3037565922165,
                0x47d742a798fbd5eb3b72891edd2e30ee,
            ),
            (
                0x2f318a0428cc1c58f669534d967f0564,
                0xf78a2b0f82734e6c3854ff278a8d3db9,
                0x6a76e9bd6cad28f24ae0ab0a328a5432,
            ),
            (
                0x7e1ab5455ebad9052b9259c8dfcbda60,
                0x3c1aa69c0b462c42f9c43d8f84c256f7,
                0x065ea9821d86bec3f9d57016fe79a3c1,
            ),
            (
                0xb9251b3fd89a5d68be01dc942cd2eaf4,
                0x8f7fcbb6ae127a6efc82888a4f564cd3,
                0xc51fcba3e16f6ffc4cd5e76d2b9d2b18,
            ),
            (
                0x60411984f3f261ae83f9bac9a882e89f,
                0x35f907b8c4148abd9e2f79ed450b1ee0,
                0xfd08c4e29085b5c9b40c8d205e3b9edc,
            ),
            (
                0x949a895338d910af681e5decaab3a393,
                0xa01933807d7521268550b6e919940e4b,
                0x1d8c5f6be4ceaa8d2cb41b5505bd846c,
            ),
            (
                0x169aa8366613a667d5696de50cfad092,
                0x148281e43db9921a43712794f24c987a,
                0xe131e1e3b540cdb51675761ad73991a4,
            ),
            (
                0x3f2ae6207c11c544eb6a3b29b9b1f846,
                0xb4b1441b102f1eef3deed8f2866ecb5d,
                0x34df145d75f362e172dc63976a9de23c,
            ),
            (
                0xa3a4f4952441718617c659ab4b838bc7,
                0xfef4e58e055b3cb8cb4f789ae43cd5cf,
                0x2e8ff2669d0f39ed034904e2b7bc38da,
            ),
        ];

        for (a, b, c) in tests {
            let a: Block = a.into();
            let b: Block = b.into();
            let c: Block = c.into();
            let a: F128 = a.into();
            let b: F128 = b.into();
            let c: F128 = c.into();
            println!(
                "a = {:?}, b = {:?}, a * b = {:?}, cmul = {:?}",
                a,
                b,
                c,
                a.cmul(b)
            );
            assert_eq!(a * b, c);
        }
    }

    #[test]
    fn test_and() {
        let x = rand::random::<Block>();
        let y = x & Block(ONES);
        assert_eq!(x, y);
    }

    #[test]
    fn test_or() {
        let x = rand::random::<Block>();
        let y = x | Block(ONES);
        assert_eq!(y, Block(ONES));
        let y = x | x;
        assert_eq!(x, y);
    }

    #[test]
    fn test_xor() {
        let x = rand::random::<Block>();
        let y = rand::random::<Block>();
        let z = x ^ y;
        let z = z ^ y;
        assert_eq!(x, z);
    }

    #[test]
    fn test_lsb() {
        let x = rand::random::<Block>();
        let x = x | Block(ONE);
        assert!(x.lsb());
        let x = x ^ Block(ONE);
        assert!(!x.lsb());
    }

    #[test]
    fn test_flip() {
        let x = rand::random::<Block>();
        let y = x.flip().flip();
        assert_eq!(x, y);
    }

    #[test]
    fn test_conversion() {
        let x = rand::random::<u128>();
        let x_ = u128::from(Block::from(x));
        assert_eq!(x, x_);
    }
}
